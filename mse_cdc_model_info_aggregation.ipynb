{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download CDC model data to designated local file saving path\n",
    "domain = 'https://www.cdc.gov'\n",
    "url = 'https://www.cdc.gov/coronavirus/2019-ncov/covid-data/forecasting-us-previous.html'\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "all_tags = soup.findAll('a')\n",
    "for tag in all_tags:\n",
    "    uri = tag['href']\n",
    "    if 'model-data' in uri:\n",
    "        res = requests.get(domain + uri)\n",
    "        content = res.content\n",
    "        file_name = uri.split('/')[-1]\n",
    "        csv_file = open('./' + file_name, 'wb')\n",
    "        csv_file.write(content)\n",
    "        csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To set jupyter note book display options, with 60 columns\n",
    "pd.options.display.max_columns=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of file names: filenames\n",
    "# Statically\n",
    "# filenames = ['2020-04-13-model-data.csv','2020-04-20-model-data.csv','2020-04-27-model-data.csv','2020-05-04-model-data.csv','2020-05-11-model-data.csv','2020-05-18-model-data.csv','2020-05-25-model-data.csv','2020-06-01-model-data.csv']\n",
    "\n",
    "# Dynamically\n",
    "filenames = [path.split('/')[-1] for path in glob.glob(os.getcwd() + '/*model-data.csv')]\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of three DataFrames: dataframes\n",
    "dataframes = []\n",
    "for filename in filenames:\n",
    "    dataframes.append(pd.read_csv(filename))\n",
    "\n",
    "#concat the list of dataframe together \n",
    "agg_models=pd.concat(dataframes)\n",
    "\n",
    "\n",
    "#add target weeks number to a new columns\n",
    "agg_models['target_week']=agg_models.target.str.extract('(\\d+)')\n",
    "agg_models.dropna(subset=['target_week'],inplace=True)\n",
    "\n",
    "#convert target week as int\n",
    "agg_models['target_week']=agg_models['target_week'].astype(int)\n",
    "agg_models.dtypes\n",
    "agg_models['target_week_end_date']=pd.to_datetime(agg_models['target_week_end_date'])\n",
    "\n",
    "\n",
    "#filter and keep only less and equal 4 weeks target week\n",
    "agg_models=agg_models[agg_models['target_week'].le(4)]\n",
    "agg_models=agg_models[~agg_models['target'].str.contains('inc')]\n",
    "\n",
    "#check inc death \n",
    "inc_death_check=agg_models['target'].isin(['inc'])\n",
    "inc_death_check.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary for abbreviation and full name (states, also convert national to US) in order to match with JHU csse\n",
    "states_abb = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming',\n",
    "        'National':'US',\n",
    "        'United States':'US',\n",
    "        \n",
    "}\n",
    "\n",
    "\n",
    "#Change all the abbreviation to full name \n",
    "for state in agg_models['location_name']:\n",
    "    if state in states_abb.keys():\n",
    "        state_1=states_abb.get(state)\n",
    "        agg_models['location_name'].replace(state,state_1,inplace=True)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "#drop duplicates\n",
    "agg_models=agg_models.drop_duplicates()\n",
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data (death data from jhu csse in the newest time)\n",
    "\n",
    "url ='https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv'\n",
    "jhu_csse = pd.read_csv(url, index_col=0)\n",
    "display(jhu_csse.head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove some geo columns and group all the counties into state level\n",
    "\n",
    "jhu_csse_st = jhu_csse.drop(jhu_csse.columns[[0, 1,2, 3,4,6,7,8,9,10,11]], axis=1) \n",
    "jhu_csse_st_grouped=jhu_csse_st.groupby(['Province_State']).sum()\n",
    "display(jhu_csse_st_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read US total confirm cases from JHU csse \n",
    "url ='https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
    "jhu_csse_ustotal = pd.read_csv(url)\n",
    "jhu_csse_ustotal = jhu_csse_ustotal.drop(jhu_csse_ustotal.columns[[0, 2, 3,4]], axis=1) \n",
    "\n",
    "\n",
    "#identify the rows \n",
    "jhu_csse_ustotal=jhu_csse_ustotal.loc[jhu_csse_ustotal['Country/Region']=='US']\n",
    "jhu_csse_ustotal.rename(columns={'Country/Region':'State'},inplace=True)\n",
    "jhu_csse_st_grouped.rename(columns={'Province_State':'State'},inplace=True)\n",
    "\n",
    "#change the index as State\n",
    "jhu_csse_ustotal=jhu_csse_ustotal.set_index('State')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append the US total confirm cases into state confirm cases\n",
    "ad_agg=jhu_csse_st_grouped.append(jhu_csse_ustotal)\n",
    "ad_agg.reset_index(level=0,inplace=True)\n",
    "ad_agg.rename(columns={'index':'State'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert wide data into long data set and unified the date formate \n",
    "ad_agg_1=ad_agg.melt(id_vars='State')\n",
    "ad_agg_1.columns=['State','Date','Death']\n",
    "ad_agg_1['Date']=pd.to_datetime(ad_agg_1['Date'])\n",
    "display(ad_agg_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agg_models\n",
    "agg_models.loc[agg_models['model']=='NotreDame-FRED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge!\n",
    "\n",
    "master=pd.merge(agg_models,ad_agg_1,how='left',left_on=['location_name','target_week_end_date'],right_on=['State','Date'])\n",
    "master=master.rename(columns={'target_week_end_date':'predict_date','location_name':'State','point':'predict_death','Date':'Actual_date','Death':'Actual_death'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.to_csv('master_predict_acutal3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculation \n",
    "clean_data=master.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax=plt.subplots()\n",
    "ax.plot(clean_data['predict_date'],clean_data['predict_death'],color='r',marker='o',linestyle='')\n",
    "ax.plot(clean_data['predict_date'],clean_data['Actual_death'],color='b',marker='o',linestyle='')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['dif']=clean_data['predict_death']-clean_data['Actual_death']\n",
    "clean_data['sq_dif']=clean_data['dif']**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Accuracy by using log\n",
    "clean_data['accuracy_pct'] = (1 - np.abs(np.log(clean_data['predict_death'].values/clean_data['Actual_death'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group_state_count=clean_data.groupby(['model','forecast_date','predict_date']).count()\n",
    "data_group_count=data_group_state_count['State']\n",
    "data_group_count.columns=['State','drop']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_count=data_group_count['State']\n",
    "state_count\n",
    "state_sum=clean_data.groupby(['model','forecast_date','predict_date']).sum()\n",
    "state_sum_1=state_sum['sq_dif']\n",
    "MSE=state_sum.merge(state_count.to_frame(), how='left',left_index=True,right_index=True)\n",
    "MSE['MSE']=MSE['sq_dif']/MSE['State']\n",
    "MSE.sort_values('MSE')\n",
    "MSE_before530=MSE.reset_index()\n",
    "# MSE_before530=MSE_before530.loc[MSE_before530['predict_date']<='2020-05-30']\n",
    "MSE_final=MSE_before530.drop(MSE_before530.columns[[6,8,9,10]],axis=1)\n",
    "MSE_final['Accuracy_0']=np.abs(np.log(MSE_final['predict_death']/MSE_final['Actual_death']))\n",
    "MSE_final['Accuracy_1']=1-MSE_final['Accuracy_0']\n",
    "MSE_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_final.loc[MSE_final['State']<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_loc=MSE_final.loc[MSE_final['forecast_date']=='2020-04-20']\n",
    "ensemble_group_created=ensemble_loc.groupby('predict_date').agg({'MSE':'mean'})\n",
    "ensemble_group=ensemble_group_created.reset_index()\n",
    "ensemble_group['model']='Ensemble'\n",
    "ensemble_group['forecast_date']='2020-04-20'\n",
    "ensemble_loc_append=ensemble_loc.copy()\n",
    "ensemble_loc_append=pd.concat([ensemble_loc_append,ensemble_group],sort=False)\n",
    "ensemble_loc_append=ensemble_loc_append.loc[ensemble_loc_append['model']=='Ensemble']\n",
    "MSE_final=pd.concat([MSE_final,ensemble_loc_append],sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 1. have every date go through validation\n",
    "# 2. If date format is correct, do nothing\n",
    "# 3. If date format is not correct, try to parse it with different format and then convert to the correct format\n",
    "\n",
    "def normalize_date_format(date_str, debug=False):\n",
    "    expected_date_format = '%Y-%m-%d'\n",
    "    date_format_variations = ['%m/%d/%Y']\n",
    "\n",
    "    try:\n",
    "        datetime.strptime(date_str, expected_date_format)\n",
    "        return date_str\n",
    "    except:\n",
    "        if debug:\n",
    "            print(\"Invalid date format found: %s\" % date_str)\n",
    "        for i, date_format_variation in enumerate(date_format_variations):\n",
    "            try:\n",
    "                if debug:\n",
    "                    print(\"Parsing incorrect date with date format variation %s: %s\" % (i+1, date_format_variation))\n",
    "                date_obj = datetime.strptime(date_str, date_format_variation)\n",
    "                updated_date_str = date_obj.strftime(expected_date_format)\n",
    "                if debug:\n",
    "                    print(\"Successfully normalized date str to expected format: %s\" % updated_date_str)\n",
    "                return updated_date_str\n",
    "            except Exception as e:\n",
    "                if debug:\n",
    "                    print(\"Failed to normalize date with date format variation %s.\" % i+1)\n",
    "\n",
    "\n",
    "\n",
    "dates = sorted([normalize_date_format(date) for date in list(set(MSE_final['forecast_date'].to_list()))])\n",
    "\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_final['forecast_date'] = MSE_final['forecast_date'].apply(normalize_date_format)\n",
    "MSE_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###heatmap modeulo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Organized and change model names\n",
    "MSE_final['model'].describe()\n",
    "Name_arr=MSE_final['model'].unique()\n",
    "Name_list=Name_arr.tolist()\n",
    "Name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###model name dictionary\n",
    "name_dictionary = {\n",
    "        'COVIDhub-ensemble': 'Ensemble',\n",
    "        'ensemble forecast': 'Ensemble',\n",
    "    \n",
    "        'GT-DeepCOVID': 'GA_Tech',\n",
    "        'IHME-CurveFit': 'IHME',\n",
    "        'Imperial-ensemble1': 'Imperial1',\n",
    "        'Imperial-ensemble2': 'Imperial2',\n",
    "        'LANL-GrowthRate': 'LANL',\n",
    "        'MIT_CovidAnalytics-DELPHI': 'MIT',\n",
    "        'MOBS_NEU-GLEAM_COVID': 'MOBS',\n",
    "        'NotreDame-FRED': 'NotreDame',\n",
    "        'UCLA-SuEIR': 'UCLA',\n",
    "        'UMass-MechBayes': 'UMass-MB',\n",
    "        'UT Austin': 'UT',\n",
    "        'UT-Mobility': 'UT',\n",
    "        'University of Geneva': 'Geneva',\n",
    "        'YYG-ParamSearch': 'YYG',\n",
    "        'Geneva-DeterministicGrowth':'Geneva'\n",
    "        \n",
    "        \n",
    "}\n",
    "\n",
    "#Change all the names that in the dictionary to common model names\n",
    "for name in MSE_final['model']:\n",
    "    if name in name_dictionary.keys():\n",
    "        name_1=name_dictionary.get(name)\n",
    "        MSE_final['model'].replace(name,name_1,inplace=True)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "#check unique\n",
    "MSE_final['model'].unique()   ##all good :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Aggregate function\n",
    "MSE_agg_mean=MSE_final.groupby(['model','forecast_date']).agg(\n",
    "    {'MSE':'mean',\n",
    "    'Accuracy_1':'mean'}\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "###fix datetime (leave it later)\n",
    "#MSE_agg_mean['forecast_date']=pd.to_datetime(MSE_agg_mean['forecast_date']).dt.strftime('%Y/%m/%d')\n",
    "\n",
    "MSE_agg_mean.loc[['IHME']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##look up Imperial, select between Imperial 1 and Imperial 2 then change the name to Imperial, fill 2020-5-18\n",
    "MSE_agg_mean.rename(index={'Imperial2':'Imperial'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSEaggmean_exclude=MSE_agg_mean.drop(['UChicago_100','UChicago_40','UChicago_60','UChicago_80','UChicago',\n",
    "                                    'CU 20% contact reduction','CU 30% contact reduction', 'CU 40% contact reduction',\n",
    "       'CU-60contact', 'CU-70contact', 'CU-80contact', 'CU-80contact_1x',\n",
    "       'CU-80contactw','Imperial1','NotreDame'])\n",
    "MSEaggmean_exclude\n",
    "\n",
    "\n",
    "###inspected the date 2020-5-11 format is not uniform, change into %y%d%m\n",
    "# MSEaggmean_exclude.rename(index={'5/11/2020':'2020-05-11'},inplace=True)\n",
    "MSEaggmean_exclude.sort_index(level=0)\n",
    "\n",
    "###convert into wide format\n",
    "MSE_wide=MSEaggmean_exclude.copy()\n",
    "MSE_wide=pd.pivot_table(MSE_wide,index=['model'],values='MSE',columns='forecast_date')\n",
    "\n",
    "# MSE_wide=MSE_wide.sort_values(by=['2020-04-13','2020-04-20','2020-04-27','2020-05-04','2020-05-11','2020-05-18','2020-05-25','2020-06-01','2020-06-15','2020-06-22'],\n",
    "#                                 na_position='last')\n",
    "MSE_wide=MSE_wide.sort_values(by=dates,\n",
    "                                na_position='last')\n",
    "\n",
    "MSE_wide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#release index to columns for heatmap dataframe structure\n",
    "\n",
    "ax=sb.heatmap(MSE_wide,annot=False,linewidth=.5,cmap='RdYlGn_r')\n",
    "ax.set(xlabel='Forecast Date',ylabel='Model',title='Mean Square Error')\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=45)\n",
    "#ax.title('Mean Sqaure Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_final.to_csv('MSE_final.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_wide.to_csv('MSE_wide.csv', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
